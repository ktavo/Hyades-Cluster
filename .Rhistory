install.packages(plotrix)
install.packages("plotrix")
install.packages("plotrix")
install.packages("plotrix")
library("plotrix", lib.loc="C:/Program Files/R/R-3.4.0/library")
install.packages("plotrix")
setInternet2(set = TRUE)
setInternet2(use = TRUE)
install.packages("plotrix")
Modelos
Modelos<-2010:2016
Modelos
Ventas<-c(2,4,0,9,3,7,6)
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(9))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(7))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(1))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(9))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(1))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(10))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(100))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(7))
plot(Modelos,Ventas,type="h",lty="solid", lwd=4, col=heat.colors(9))
hist(PESO, col=maroon1, density=18, border= bluevliolet)
hist(PESO,col="maroon1",breaks=seq(0,85,5),density=18,angle=70)
no.gar=c(258,280)
gar.si=c(184,719)
mat=rbind(no.gar,gar.si)
colnames(mat)=c("no.cons","si.cons")
mosaicplot(mat,col=terrain.colors(2:3),main="Gráfico de mosaicos")
mosaicplot(mat,col=terrain.colors(2:3),main="Gráfico de mosaicos")
install.packages(plotrix)
install.packages("plotrix")
read.csv2("E:/UBA/Análisis Inteligente de Datos/1- 8 de abril - 14 de abril/movies.csv")
moviesDB <- read.csv2("E:/UBA/Análisis Inteligente de Datos/1- 8 de abril - 14 de abril/movies.csv")
attach(moviesDB)
frec.tipo <- (table(3))
etiquetas<-c("Comedy"; "Romance"; "Children"; "Adventure")
etiquetas<-c("Comedy", "Romance", "Children", "Adventure")
pie3D(frec.tipo,labels=etiquetas,explode=0.3,labelcex=0.8,radius=1.5)
install.packages("pie3D")
ap <- available.packages()
ap
install.packages("pie3d")
install.packages("pie3D")
recepcionistasDB <- read.csv2("E:/UBA/Análisis Inteligente de Datos/4- 29 de abril - 5 de mayo/recepcionistas.xls")
recepcionistasDB <- read.csv2("E:/UBA/Análisis Inteligente de Datos/4- 29 de abril - 5 de mayo/recepcionistas.xls")
recepcionistasDB <- read.csv2("E:/UBA/Análisis Inteligente de Datos/4- 29 de abril - 5 de mayo/recepcionistas.csv")
recepcionistasDB
recepcionistasDB
recepcionistasDB <- read.csv2("E:/UBA/Análisis Inteligente de Datos/4- 29 de abril - 5 de mayo/recepcionistas.csv")
recepcionistasDB
View(recepcionistasDB)
total <-rowMeans(recepcionistasDB)
total <-rowMeans(recepcionistasDB, -ncol(1))
total <-rowMeans(recepcionistasDB[, -ncol(1)])
> recepcionistasDB$mean <- rowMeans(subset(recepcionistasDB, select = c(2, 7)), na.rm = TRUE)
recepcionistasDB$mean <- rowMeans(subset(recepcionistasDB, select = c(2, 7)), na.rm = TRUE)
recepSubset = subset(recepcionistasDB, select = c(2,7))
recepSubset
View(recepSubset)
View(recepSubset)
View(recepSubset)
remove(recepSubset)
View(recepSubset)
View(recepcionistasDB)
recepcionistasDB$mean <- rowMeans(subset(recepcionistasDB, select = c(2; 7)), na.rm = TRUE)
recepcionistasDB$mean <- rowMeans(subset(recepcionistasDB, select = c(2: 7)), na.rm = TRUE)
View(recepcionistasDB)
recepcionistasDB$juez1 <- rowMeans(subset(recepcionistasDB, select = c(2: 4)), na.rm = TRUE)
recepcionistasDB$juez2 <- rowMeans(subset(recepcionistasDB, select = c(5: 7)), na.rm = TRUE)
View(recepcionistasDB)
recepcionistasDBNormalizada <- subset(recepcionistasDB, select = c(2:7))
recepcionistasDBNormalizada
view(recepcionistasDBNormalizada)
recepcionistasDBNormalizada <- scale(recepcionistasDBNormalizada)
view(recepcionistasDBNormalizada)
view(recepcionistasDB)
View(recepcionistasDBNormalizada)
meantest <- rowMeans(subset(recepcionistasDBNormalizada, select = c(1: 6)), na.rm = TRUE)
meantest
meantest <- rowMeans(recepcionistasDBNormalizada)
View(meantest)
View(recepcionistasDBNormalizada)
remove(meantest)
recepcionistasDBNormalizada <- scale(recepcionistasDBNormalizada, 0 ,1)
recepcionistasDBNormalizada <- rnorm(recepcionistasDB)
View(recepcionistasDBNormalizada)
View(recepcionistasDB)
recepcionistasDBNormalizada <- rnorm(subset(recepcionistasDB, select = c(2:7)))
View(recepcionistasDBNormalizada)
remove(recepcionistasDBNormalizada)
pointsRecepcionistas <- subset(recepcionistasDB, select = c(2:7))
View(pointsRecepcionistas)
normalizedPoints <- rnorm(pointsRecepcionistas)
View(normalizedPoints)
remove(normalizedPoints)
View(recepcionistasDB)
normalizedDB <- apply(recepcionistasDB, [,2], 1 , scale)
normalizedDB <- apply(recepcionistasDB[,2], 1 , scale)
install.packages("scales")
normalizedRecepcionistasDB <- rescale(pointsRecepcionistas)
library("scales")
normalizedRecepcionistasDB <- rescale(pointsRecepcionistas)
View(pointsRecepcionistas)
normalizedRecepcionistasDB <- rescale(pointsRecepcionistas, to c (-1,1))
normalizedRecepcionistasDB <- rescale(pointsRecepcionistas, to=c(-1,1))
normalizedRecepcionistasDB <- apply(pointsRecepcionistas, 2, sum)
normalizedRecepcionistasDB
normalizedRecepcionistasDB <- apply(pointsRecepcionistas, 2, rescale)
normalizedRecepcionistasDB
normalizedRecepcionistasDB <- apply(pointsRecepcionistas, 2, rescale, (-1,1))
normalizedRecepcionistasDB <- apply(pointsRecepcionistas, 2, rescale(-1,1))
normalizedRecepcionistasDB <- apply(pointsRecepcionistas, 2, rescale, to=c(-1,1))
normalizedRecepcionistasDB
rowMeans <- apply(normalizedRecepcionistasDB, 2 , colMeans)
View(normalizedRecepcionistasDB)
pointsRecepcionistas
install.packages("ca")
library("ca")
fum = matrix  (c(4,2,3,2,4,3,7,4,25,10,12,4,18,24,33,13,10,6,7,2))
fum
View fum
View(fum)
fum = matrix  (c(4,2,3,2,4,3,7,4,25,10,12,4,18,24,33,13,10,6,7,2), nrow = 5, ncol = 4, byrow = TRUE)
View(fum)
tabum = addmargins(fum)
View(tabum)
colnames(fum) = c("NoFuma", "Poco", "Medio", "Mucho", "TotalFila")
colnames(tabum) = c("NoFuma", "Poco", "Medio", "Mucho", "TotalFila")
rownames(tabum) = c("G.Senior", "G.Junior", "EmpSenior", "EmpJunior", "Secretarira", "Total_Col")
View(tabum)
objeto = ca(tabum, nd=2)
plot(objeto, main="Biplot Simétrico")
Arbequina=c(34.5, 20.1, 21.8 ,18.2 ,19.5 ,20.2,22.5 ,23.9 ,22.1 ,24.2)
Carolea=c (16.4, 14.8, 17.8, 12.3, 11.9, 15.5, 13.4,16 ,15.8 ,16.2)
shapiro.test(Arbequina) # testeamos la normalidad de los datos
shapiro.test(CArolea) # testeamos la normalidad de los datos
shapiro.test(Carolea) # testeamos la normalidad de los datos
wilcox.test(Arbequina,Carolea, alternative="two.sided") # aplicamos el test de Mann Whitney
Wilcoxon bilateral
wilcox.test(Arbequina,Carolea, alternative="two.sided") # aplicamos el test de Mann Whitney
#Los datos no satisfacen el supuesto de normalidad distribucional, luego no puede aplicarse un test t.
library(RVAideMemoire)
install.packages("RVAdeMemoire")
install.packages("RVAideMemoire")
library(RVAideMemoire)
#te.aov<-aov(vitam  marca) # cargamos el análisis de la varianza en el objeto te.aov
#summary(te.aov) # pedimos la síntesis de la prueba
#bartlett.test(vitam,marca)
install.packages("Rcmdr)")
install.packages("Rcmdr")
install.packages("reshape2")
install.packages("car")
install.packages("car")
library("Rcmdr")
install.packages("nortest")
#Modelo con libreria  rpart con busqueda  Grid Search
#Estimo la ganancia con  Repeated Random Sub Sampling Validation   ( Monte Carlo Cross Validation )
#Por favor, no desesperarse por la ESPANTOSA granularidad de la Grid Search
#notar el uso de CPU y memoria RAM
#Si este programa se corta,  se lo debe volver a correr y automaticamente retoma desde donde llego la vez anterior
#Estadisticos y actuarios no entren en panico porque estamos entrenando y evaluando en el mismo mes, ya vamos a mejorar
#exp-1100
#source( "~/cloud/cloud1/codigoR/rpart/rpart_tune_gridsearch_01.r" )
#limpio la memoria
rm( list=ls() )
gc()
library( "rpart" )
library( "data.table" )
library( "caret" )
switch ( Sys.info()[['sysname']],
Windows = { directory.include  <-  "M:\\codigoR\\include\\"
directory.work     <-  "M:\\work\\"
directory.plan     <-  "M:\\plan\\"
directory.datasets <-  "M:\\datasets\\"
},
Darwin  = { directory.include  <-  "~/dm/codigoR/include/"
directory.work     <-  "~/dm/work/"
directory.plan     <-  "~/dm/plan/"
directory.datasets <-  "~/dm/datasets/"
},
Linux   = { directory.include  <-  "~/cloud/cloud1/codigoR/include/"
directory.work     <-  "~/cloud/cloud1/work/"
directory.plan     <-  "~/cloud/cloud1/plan/"
directory.datasets <-  "~/cloud/cloud1/datasets/"
}
)
setwd( directory.include )
source( "metrica.r" )
#Parametros entrada de nuestro dataset
karchivo_entrada      <-  "201802.txt"
kcampos_separador     <-  "\t"
kcampo_id             <-  "numero_de_cliente"
kclase_nomcampo       <-  "clase_ternaria"
kclase_valor_positivo <-  "BAJA+2"
kcampos_a_borrar      <-  c( kcampo_id )
#Parametros  Repeated Random Sub Sampling Validation
ktraining_prob        <-  0.70
ksemilla_azar         <-  c( 102191, 200177, 410551, 552581, 892237 )
karchivo_salida       <-  "hyperparameter_GLOBAL.txt"
#estos valores se graban en el archivo de salida
kexperimento          <-  1100
kclase                <-  "ternaria"
kprograma             <-  "rpart_tune_gridsearch_01.r"
kalgoritmo            <-  "rpart"
kbusqueda             <-  "gridsearch"
kestimacion           <-  "Montecarlo"
kobservaciones        <-  "5 semillas"
#------------------------------------------------------
#Genera el modelo usando una semilla
modelo_rpart_uno = function( psemilla, pmaxdepth, pminbucket, pminsplit, pcp )
{
set.seed( psemilla )
inTraining        <-  createDataPartition( dataset[ , get(kclase_nomcampo)],   p = ktraining_prob, list = FALSE)
dataset_training  <-  dataset[  inTraining, ]
dataset_testing   <-  dataset[ -inTraining, ]
# generacion del modelo
formula  <-  formula( paste(kclase_nomcampo, "~ .") )
t0       <-  Sys.time()
modelo   <-  rpart( formula,   data = dataset_training,  xval=0, maxdepth=pmaxdepth, minbucket=pminbucket, minsplit=pminsplit, cp=pcp )
t1       <-  Sys.time()
tiempo <-  as.numeric(  t1 - t0, units = "secs")
#aplico el modelo a datos nuevos
testing_prediccion  <- predict(  modelo, dataset_testing , type = "prob")
# calculo la ganancia normalizada  en testing
gan <-  fmetrica_ganancia_rpart( testing_prediccion[, kclase_valor_positivo ],  dataset_testing[ , get(kclase_nomcampo)] ) / ( 1- ktraining_prob )
# calculo el AUC en testing
auc <- fmetrica_auc_rpart( testing_prediccion[ ,kclase_valor_positivo],  dataset_testing[ , get(kclase_nomcampo)] )
return(  list( "ganancia"=gan,  "tiempo"= tiempo,  "auc"=auc )  )
}
#------------------------------------------------------
#corre  rpart  usando  las semillas, y promedia el resultado
modelo_rpart_ganancia = function( dataset, pmaxdepth, pminbucket, pminsplit, pcp  )
{
res  <-   lapply( ksemilla_azar, modelo_rpart_uno, pmaxdepth=pmaxdepth,  pminbucket=pminbucket, pminsplit=pminsplit, pcp=pcp )
return(  list( "ganancia" = unlist( lapply( res, '[[', "ganancia" ) ),
"tiempo"   = unlist( lapply( res, '[[', "tiempo" ) ),
"auc"      = unlist( lapply( res, '[[', "auc" ) )
)
)
}
#------------------------------------------------------
#cargo los datos
setwd( directory.datasets )
dataset <- fread( karchivo_entrada, header=TRUE, sep=kcampos_separador )
#borro las variables que no me interesan
dataset[ ,  (kcampos_a_borrar) := NULL    ]
#escribo los  titulos  del archivo salida
setwd( directory.work )
if( !file.exists( karchivo_salida) )
{
cat("experimento",
"metrica",
"metrica2",
"tiempo",
"parametros",
"fecha",
"clase", "programa", "algoritmo", "busqueda" , "estimacion",
"dataset_train", "dataset_test", "observaciones",
"\n", sep="\t", file=karchivo_salida, fill=FALSE, append=FALSE )
lineas_salida <- 0
} else
{
salida <-  read.table( karchivo_salida, header=TRUE, sep=kcampos_separador )
lineas_salida <- nrow( salida )
}
linea <- 1
for( vcp  in  c( 0, 0.0005,  0.001, 0.005 ) )
{
for( vminsplit  in  c(  2, 5, 10, 20, 50, 100, 200, 400, 500, 800, 1000 )  )
{
for( vminbucket  in  c( trunc(vminsplit/4), trunc(vminsplit/3) )  )
{
for(  vmaxdepth  in  c(  4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30 ) )
{
if( linea > lineas_salida )  #no volver a procesar si en la corrida anterior se llego a esa lina
{
res <- modelo_rpart_ganancia( dataset, pmaxdepth=vmaxdepth, pminbucket=vminbucket, pminsplit=vminsplit, pcp=vcp  )
#genero el string con los parametros
st_parametros = paste( "xval=",      0,          ", " ,
"maxdepth=",  vmaxdepth,  ", " ,
"minbucket=", vminbucket, ", " ,
"minsplit=",  vminsplit,  ", " ,
"cp=",        vcp,
sep = ""
)
cat( kexperimento,
mean(res$ganancia),
mean(res$auc),
sum(res$tiempo),
st_parametros,
format(Sys.time(), "%Y%m%d %H%M%S"),
kclase,
kprograma,
kalgoritmo,
kbusqueda,
kestimacion,
karchivo_entrada, karchivo_entrada,
kobservaciones,
"\n", sep="\t", file=karchivo_salida, fill=FALSE, append=TRUE
)
}
linea <- linea+1
}
}
}
}
#limpio la memoria
rm( list=ls() )
gc()
#salgo del R sin grabar el gigante entorno
quit( save="no" )
rm(list=ls())
setwd("E:/UBA/2018-II/DM en Ciencia y Tecnología/Hyades")
library("gdata")
hipparcos = read.xls("datasets/hyades_source.xlsx",
sheet=1)
hipparcos = read.xls("datasets/hyades_source.xlsx",
sheet=1)
symbad <- read.csv(file="datasets/Symbad.csv", header=TRUE, sep=";")
tycho <- read.csv(file="datasets/Tycho.csv", header=TRUE, sep=";")
hipparcos <- read.csv(file="datasets/hipparcos.csv", header=TRUE, sep=";")
View(hipparcos)
View(hipparcos)
hipparcos$RA_J2000 <- as.numeric(hipparcos$RA_J2000)
hipparcos$DE_J2000 <- as.numeric(hipparcos$DE_J2000)
hipparcos$Plx <- as.numeric(hipparcos$Plx)
hipparcos$pmRA <- as.numeric(hipparcos$pmRA)
hipparcos$pmDE <- as.numeric(hipparcos$pmDE)
hipparcos$Vmag <- as.numeric(hipparcos$Vmag)
hipparcos$B_V <- as.numeric(hipparcos$B_V)
hip.pca.cov = prcomp(hipparcos, center = TRUE, scale. = FALSE)
hipparcos_numeric = data.frame(hipparcos[,2:8])
hipparcos_numeric
hip.pca.cov = prcomp(hipparcos_numeric, center = TRUE, scale. = FALSE)
hip.pca.cov
hip = prcomp(hipparcos_numeric, center = TRUE, scale. = FALSE)
rm(list=ls())
setwd("E:/UBA/2018-II/DM en Ciencia y Tecnología/Hyades")
symbad <- read.csv(file="datasets/Symbad.csv", header=TRUE, sep=";")
tycho <- read.csv(file="datasets/Tycho.csv", header=TRUE, sep=";")
hipparcos <- read.csv(file="datasets/hipparcos.csv", header=TRUE, sep=";")
hipparcos$RA_J2000 <- as.numeric(hipparcos$RA_J2000)
hipparcos$DE_J2000 <- as.numeric(hipparcos$DE_J2000)
hipparcos$Plx <- as.numeric(hipparcos$Plx)
hipparcos$pmRA <- as.numeric(hipparcos$pmRA)
hipparcos$pmDE <- as.numeric(hipparcos$pmDE)
hipparcos$Vmag <- as.numeric(hipparcos$Vmag)
hipparcos$B_V <- as.numeric(hipparcos$B_V)
#Realiza el análisis de componentes principales
hip.pca.cov = prcomp(hipparcos, center = TRUE, scale. = FALSE)
#Realiza el análisis de componentes principales con las variables estandarizadas
hip.pca.cor = prcomp(hipparcos_numeric, center = TRUE, scale. = FALSE)
hipparcos_numeric = data.frame(hipparcos[,2:8])
#Realiza el análisis de componentes principales
hip.pca.cov = prcomp(hipparcos_numeric, center = TRUE, scale. = FALSE)
#Realiza el análisis de componentes principales con las variables estandarizadas
hip.pca.cor = prcomp(hipparcos_numeric, center = TRUE, scale. = FALSE)
summary(hip.pca.cov)
summary(hip.pca.cor)
matrizCorrelacion = cor(hipparcos_numeric)
matrizCorrelacion
corrplot.mixed(matrizCorrelacion, lower = "number", upper = "shade", addshade = "all")
library("corrplot")
corrplot.mixed(matrizCorrelacion, lower = "number", upper = "shade", addshade = "all")
corrplot.mixed(matrizCorrelacion, lower = "number", upper = "shade", addshade = "all")
summary(hip.pca.cov)
symbad <- read.csv(file="datasets/Symbad.csv", header=TRUE, sep=";")
symbad$RA <- as.numeric(symbad$RA)
symbad$RA_J2000 <- as.numeric(symbad$RA_J2000)
symbad$DE <- as.numeric(symbad$DE)
symbad$DE_J2000 <- as.numeric(symbad$DE_J2000)
symbad_numeric = data.frame(symbad[,5:8])
sym.pca.cov = prcomp(symbad_numeric, center = TRUE, scale. = FALSE)
summary(sym.pca.cov)
matrizCorrelacion = cor(symbad_numeric)
matrizCorrelacion
matrizCorrelacionHipparcos = cor(hipparcos_numeric)
corrplot.mixed(matrizCorrelacionHipparcos, lower = "number", upper = "shade", addshade = "all")
corrplot.mixed(matrizCorrelacionSymbad, lower = "number", upper = "shade", addshade = "all")
matrizCorrelacionSymbad = cor(symbad_numeric)
corrplot.mixed(matrizCorrelacionSymbad, lower = "number", upper = "shade", addshade = "all")
tycho <- read.csv(file="datasets/Tycho.csv", header=TRUE, sep=";")
View(matrizCorrelacion)
View(matrizCorrelacion)
rm(matrizCorrelacion)
rm(hip.pca.cor)
tycho$RA_J2000_24 <- as.numeric(tycho$RA_J2000_24)
tycho$DE_J2000 <- as.numeric(tycho$DE_J2000)
tycho$pmRA <- as.numeric(tycho$pmRA)
tycho$pmDE <- as.numeric(tycho$pmDE)
tycho$BT <- as.numeric(tycho$BT)
tycho$VT <- as.numeric(tycho$VT)
tycho$V <- as.numeric(tycho$V)
tycho$B.V <- as.numeric(tycho$B.V)
tycho$Plx <- as.numeric(tycho$Plx)
tycho_numeric = data.frame(tycho[,5:15])
tyc.pca.cov = prcomp(tycho_numeric, center = TRUE, scale. = FALSE)
tycho_numeric$HD <- NULL
tycho_numeric$HIP <- NULL
tyc.pca.cov = prcomp(tycho_numeric, center = TRUE, scale. = FALSE)
summary(tyc.pca.cov)
matrizCorrelacionTycho = cor(tycho_numeric)
matrizCorrelacionTycho
corrplot.mixed(matrizCorrelacionTycho, lower = "number", upper = "shade", addshade = "all")
library(FactoMineR)
library(factoextra)
library(cluster)
library("PerformanceAnalytics")
install.packages("PerformanceAnalytics")
library("PerformanceAnalytics")
chart.Correlation(hip2, histogram = TRUE)
library(ggcorrplot)
install.packages("ggcorrplot")
install.packages('PerformanceAnalytics', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('ggcorrplot', dependencies=TRUE, repos='http://cran.rstudio.com/')
corr <- round(cor(hip2[, -c(1,9)]), 1)
chart.Correlation(hip2, histogram = TRUE)
library(FactoMineR)
library(factoextra)
library(cluster)
library("FactoMineR")
library("factoextra")
library("cluster")
chart.Correlation(hip2, histogram = TRUE)
chart.Correlation(hipparcos, histogram = TRUE)
library("PerformanceAnalytics")
chart.Correlation(hipparcos, histogram = TRUE)
chart.Correlation(hip2, histogram = TRUE)
chart.Correlation(hipparcos, histogram = TRUE)
chart.Correlation(hipparcos_numeric, histogram = TRUE)
hipparcos_numeric
corr <- round(cor(hipparcos_numeric[, -c(1,9)]), 1)
corr
ggcorrplot(corr, hc.order = TRUE, lab = TRUE)
install.packages('ggcorrplot', dependencies=TRUE, repos='http://cran.rstudio.com/')
ggcorrplot(corr, hc.order = TRUE, lab = TRUE)
ggcorr(corr, hc.order = TRUE, lab = TRUE)
library(ggplot2)
plotmatrix(hip2[, - c(1, 9)])
library(GGally)
ggpairs(hip2[, - c(1, 9)], aes(alpha = 0.4))
ggpairs(hipparcos_numeric[, - c(1, 9)], aes(alpha = 0.4))
hyadeship = read.csv("datasets/hyades_en_pdf_hyparcos.csv", sep = ";")
table(hyadeship$MIEMBRO)
hip2 <- read.csv("datasets/data.csv")
hip2$miembro <- as.factor(hip2$miembro)
hiparscaled <- scale(hip2[, 2:8])
hiparscaled
rownames(hiparscaled) <- hip2$HIP
res.pca <- PCA(hiparscaled, graph = FALSE)
fviz_pca_ind(res.pca, geom = "point", col.ind = hip2$miembro)
#contribucion de variables
fviz_pca_var(res.pca, alpha.var = "contrib", select.var = list(contrib = 10)) +
theme_minimal()
fviz_pca_biplot(res.pca, label = "var", alpha.var = "contrib", habillage = hip2$miembro, repel = T)
res.pca
hiparscaled
hip2
fviz_pca_ind(res.pca, geom = "point", ¬col.ind = hip2$miembro)
fviz_pca_ind(res.pca, geom = "point", col.ind = hip2$miembro)
fviz_pca_var(res.pca, alpha.var = "contrib", select.var = list(contrib = 10)) +
theme_minimal()
